Stream Reasoning (SR) is a multidisciplinary research field. It focuses on developing and supporting methods and tools to continuously answer complex queries on a variety of fast flowing information. Example of queries across multiple social media stream are: "\textit{What are the top five trend topics, under discussion, and who is driving the discussions in Dayton?}" or "\textit{How a certain event in Milan influences the user activity?}". However, the application domains of SR are not limited to social media analytics only. Semantic interpretation of sensor data, traffic monitoring and stream data integration are all possible use cases for SR \cite{DBLP:journals/expert/ValleCHF09}.

Stream Reasoning research aims of integrating data streams and reasoning systems to answer queries. It has already posed theoretical formalisations that go beyond DSMS, CEP  \cite{DBLP:conf/debs/KomazecCF12, Lephuoc2011, 4618773} and it has defined good basis to semantically handle Data Stream encoded in RDF \cite{DBLP:conf/fis/ValleCBBC08, DBLP:journals/sigmod/BarbieriBCVG10}. Despite Stream Reasoning application domains are heterogeneous and wide, recent works have demonstrated that reasoning upon rapidly changing information is possible. Successful application of SR techniques were applied for sensor data stream integration \cite{DBLP:journals/ijswis/CalbimonteJCA12,DBLP:journals/ws/LecueTHTBST14} and Social Media Analytics \cite{DBLP:journals/ws/BalduiniCDVHLKT12}

The number of implemented solutions is rising and the need of standards and evaluation method is consequently growing too. Nowadays the SR community\footnote{\url{http://www.w3.org/community/rsp/}} is focusing on the formalisation of data, protocols an methods for RSP Engine development, but also benchmarks and evaluation frameworks to compare the results are required.


\section{Related Works \& Motivations}\label{sec:motivations-intro}

Stream Reasoning over RDF-Encoded information flows (formally, RDF Streams) has its foundations in DSMS and CEP research field and RDF reasoning theories and technologies. Nowadays, the community is focused on the formalization of three points:  (i) a data model for RDF stream; (ii) syntax and semantics of an extensions of SPARQL for continuous query answering under different entailment regimes; (iii) a protocol to interact with an RDF Stream Processing Engine (shortly, RSP Engine). 

RDF Stream standardization was developed in early works \cite{DBLP:journals/expert/ValleCHF09, Lephuoc2011} and recently extended \cite{DBLP:conf/semweb/BalduiniVDTPC13}. Continuous extensions of SPARQL, like C-SPARQL, are mature and their development is proceeding \cite{Barbieri2010}. Last but not least, many works in the field  \cite{Zhang2012,LePhuoc2012c}  try to provide benchmarks and frameworks in order to evaluate all the RSP Engine implementations proposed. 

What it is still missing is a systematic comparison of RSP Engines under repeatable conditions. As in many other fields of Computer Science, the researchers focused to model proposals and implementations only, lacking methods and tools to empirically evaluate complete systems \cite{Perry:2000:ESS:336512.336586}. A Comparative approach is required to improve SR research, which is being part of an engineering epistemology as many works have pointed out \cite{Tichy:1995:EEC:209090.209093,Wainer:2009:EEC:1518331.1518552}.

Actually RDF streams, continuous queries, and performance measurements for benchmarking RSP Engines were proposed \cite{LePhuoc2012c,Zhang2012, DBLP:conf/semweb/DellAglioCBCV13}. However the community still lacks an infrastructure for rigorous comparative research, which provides repeatability and reproducibility of typical of experiments.

%\section{ Limitations}\label{sec:related-works-intro}

\section{Research Question}\label{sec:research-question-intro}

In Section \ref{sec:motivations-intro} we present which lack affects the empirical evaluation of RSP Engines as a challenge for the current SR research. The number of the involved variables, together with the complex and multifaceted nature of RSP Engines, motivate the difficulties of conducting realistic evaluations, but it does not legitimate the lack. Research fields like economy \cite{CBO9781139174053A009}, history \cite{CSS:4411600}, psychology and other social sciences \cite{felsenstein1985phylogenies}, in which the subjects complexity is too high to be simplified into models and thus investigated, typically apply a Systematic Comparative Research Approach (SCRA).

Other engineering areas give a central role to empirical evaluation. The aerospace engineering, for example, enables experiments design, their systematic execution and the automatic comparison of results trough the usage of \textit{Engine Test Stand}. Such a tool allows an engine to be evaluated not only from an architectural viewpoint, but during the working state within a controlled experimental environment.

Existing queries, dataset and methods partially answer the problem of SR community to support SRCA on RSP Engines. It is possible to evaluate RSP Engines, but it is hard to make it systematically. Thus, we can formulate our research question as: "\textit{Can an engine test stand, together with queries, datasets and methods, support SCRA for Stream Reasoning?}".

\section{Heaven}\label{sec:heaven-intro}

This thesis work tries to answer the research question posed in Section \ref{sec:research-question-intro}: "\textit{Can an engine test stand, together with queries, datasets and methods, support SCRA for Stream Reasoning?}". We propose the description of \name -- a proposal for an RSP Engine test stand, four baseline RSP Engines and the Analyser, whose aim is enabling rigorous comparative research of RSP engines. 

\name is a modular and extendible software environment for automated evaluating of RSP Engines. 

The aerospace engineering inspired the development of a \textbf{Test Stand}, which allows design and run experiments over RSP Engines. The \textbf{Test Stand} accepts input RDF streams trough the \textbf{Streamer} specific module; it gathers performance measures during the experiment execution and it saves this data trough the \textbf{Result Collector} module, allowing post-experimental analysis.

The framework ensures the analysis trough the \textbf{Analyser}, which consists of a set of methods and tools for the RSP Engine performances investigation. The Analyser methods describe how to drill down the analysis trough different levels of details, while the tool-set allows to visualise, analyse and compare experiments w.r.t the required analysis level. 

Last but not least, \name also includes four \textbf{baseline} implementations of RSP Engines under the $\rho$DF \cite{DBLP:conf/esws/MunozPG07} entailment regime. The Baselines can be exploited  as Simple, Eligible, Relevant and Elementary (Section \ref{sec:requirements}) terms of comparison.  

Finally, this thesis work brings an experimental evidence of \name potential. We include an example of RSP Engine comparison evaluating \name Baselines. %We adapt LUBM generator to a streaming scenario trough a specific implementation of the \textbf{Streamer}. 
The insights we gathered from those experiments demonstrate how \name can lead to empirical evaluation of RSP Engines, enabling SCRA for the Stream Reasoning research field.

The entire \name (i.e., the test stand, the four baselines and the analyser) are released open source\footnote{\url{https://github.com/streamreasoning/HeavenTeststand}} with the intention to foster comparative research of RSP Engines.

\section{Outline of this Thesis}\label{sec:thesis-structure-intro}

This thesis is organized as follow:

\begin{itemize}

\item \textbf{Chapter \ref{chap:background}} contains an overview of the main research areas related to this thesis, like Semantic Web, Software Testing and Benchmarking. It also presents a background of the Stream Reasoning research field from the DSMS and CEP point view.
\item \textbf{Chapter \ref{chap:problem-settings}} describes the motivations that inspired our work. It formulate our research question and the requirements \name must satisfy to successfully answer the question.
\item \textbf{Chapter \ref{chap:heaven}} introduces \name design. It describes the \textit{Test Stand} and the \textit{Baselines} and the \textit{Analyser} methodological approach.
\item \textbf{Chapter \ref{chap:implementation-experience}} contains the details of \name implementation. How we realised the Test Stand; how the baselines were developed and finally which tools compose the Analyser.
\item \textbf{Chapter \ref{chap:evaluation}} describes the experiment design process we followed. It provides the evaluation of \name Baselines as an empirical proof of the Test Stand potential.
\item \textbf{Chapter \ref{chap:conclusions}} draws the conclusion of this thesis work and it proposes the future extensions of our research.
\end{itemize}