Stream Reasoning (SR) research field is grown enough to prove that reasoning upon rapidly changing information is possible. RDF Stream Processing (RSP) Engines, systems capable to handle at semantic level RDF-encoded information flows, are increasing in number of implemented solutions. Now the Stream Reasoning community is working on the standardisation of the methods and tools that supported their development. 

Many Computer Science (CS) research fields shown their interest for a deeper comprehension of their own work nature. Studies like~\cite{Tichy:1995:EEC:209090.209093, Wainer:2009:EEC:1518331.1518552} investigated the publications in those field, highlighting that the majority of them are allied to an Engineering epistemology. However, they also evinced and criticised the concrete differences with other engineering research areas, which focus on evaluation of the proposed systems and not only on their design and development. 

The lacks of an empirical approach can be ascribed to the complex nature of the software systems. However, it is possible to face such studies that can not be easily modelled, reducing the complexity of the analysis keeping intact the relevance of each involved system. In social science and economy, where researchers deal with cross case studies, it is commonly used a Systematic Comparative Research Approach (SCRA) within an experimental setting, which grants properties like repeatability, reproducibility and comparability to build the evaluation upon.

The SR community agreed that it is mandatory evaluating RSP Engines, understanding how these systems perform in real uses cases. Recent works in the filed~\cite{Zhang2012, LePhuoc2012c, DBLP:conf/semweb/DellAglioCBCV13} pursued this goal, providing benchmarks for RSP Engines evaluation. Further analysis pointed out the challenges involved by the Stream Reasoning research and posed the basis for a proper RSP Engines evaluation, describing in detail where previous works have failed and how the can be improved~\cite{DBLP:conf/esws/ScharrenbachUMVB13}.

The limitations of the existing benchmarking proposals proved that the empirical evaluation of RSP Engines is just at the beginning. What is still missing in an infrastructure that allows to compare, possibly automatically, the performances of many RSP Engines and that grants the properties of an experimental setting. In this thesis we brace this challenge borrowing from the aerospace engineering the idea of an engine test stand, which is an automatic facility for engine testing and development. 

A test stand allows to design experiments and to execute them, evaluating engines in a controlled environment. Thus, we formulate the following research question: "\textit{Can an engine test stand, together with queries, datasets and methods, support Systematic Comparative Research Approach for Stream Reasoning?}"

In this thesis we propose \namens, an open source framework that enables the Systematic Comparative Approach in the Stream Reasoning research field. \name consists of:  an RSP Engine Test Stand, which emulates the aerospace engineering facility in the Stream Reasoning context; the Analyser, which enables the Systematic Comparative Approach trough a set of methods and tools for the investigation, hierarchically organised into a stack; and, finally, four naive implementations of RSP Engines, called Baselines, which represent simple terms of comparison to start the comparative research upon.